Multiple camera video synchronization is a research area within multimedia. Automatic video synchronization (AVS) is a form to synchronize multiple video streams. AVS can be done analysing video segments \cite{wang2014videosnapping} or audio ones \cite{su2012making}. In Schweiger et.al.\cite{schweiger2013fully} we find these and other approaches in the area. One main contribution of this paper is the description of the challenges for automatic synchronization algorithms: wide baselines, camera motion, dynamic backgrounds and Occlusions.

We propose in this work the use of crowdosurcing techniques to synchronize these videos, instead of an automatic one. Crowdsourcing \cite{howe2006rise} in our scope refers to the use of the crowd as part of a computational problem that can be solved easily by a human than by a machine. The "easily" word can mean that the human approach: is cheaper, faster or can be done more efficiently by humans.

In video synchronization, we know that humans can fulfil all challenges presented by \cite{schweiger2013fully}. A person can identify if two videos are synchronized or not independently of occlusions, change of the background, camera motion or view point changes. The main challenge is how to use the human abilities to synchronize the videos, and permit that other persons can benefit from these contributions. So our tool uses the power of the crowd to synchronize live streaming videos and provide a form that other persons that want to watch those videos can receive both videos and synchronization info.

The remaining of this paper is presented as follows: section 2 explains our approach to synchronize videos; section 3 details our tool; and section 4 presents our final remarks.


%%%%%%%%%%%%%% ACM %%%%%%%%%%

%Nowadays users don't need to rent fancy and expensive devices, neither depended on professionals to produce and share video, they can with their mobiles create User Generated Video (UGV). UGV is a kind of multimedia content created by heterogeneous users, shared online and without any explicit coordination mechanism. UGVs can be grouped around an event: a particular geographical space shared by a group of people at a particular period of time, such as protests, music festivals or sport games, resulting in awesome enahnced contents that can be reused in many ways. Moreover, each one of these videos reveals a unique point of view about what is happening, according to the user's identity and beliefs (in terms of ideology, team and group identification etc.) as well as user's context and preferences (in terms of positioning, device capabilities and limitations etc.). 

%In this scenario, it is impossible to ensure that all the UGV related to a same significant moment in a social event will be stable, have similar visual and aural quality or even if this moment was captured by the user. Then, automatic video synchronization techniques are not so effective. The synchronization of UVG about a particular topic or event can be announced as storytelling problem. Intuitively, this problem can also viewed as a synchronization problem, in which all of the related contents must be, firstly, positioned in a same global timeline and, in the sequence, arranged to produce a coherent narrative flowing.

%Focused on this scenario, this paper introduces the idea of using crowdsourcing techniques for UGV synchronization, once the human processing is less affected by the heterogeneity of UGV content. Hence, we claim that the process of finding the synchronization points between UVG should involve crowd workers when automatic techniques are not effective. Also, the announced synchronization problem must consider many issues and in this paper, we focus on a particular issue: how to manage both crowd and video synchronization information and use them to rebuild the story of an event. In this sense, the paper introduces the Dynamic Alignment List (DAL), a data structure to assist the crowd contributions process as well as the generation of a coherent presentation of an event using UVG content. 

%We conducted three experiments to to investigate if the crowd would perform the proposed approach: the first used a crowd simulator to verify the DAL capability of managing videos and contributions, generating coherent presentations from user generated videos; the second experiment used a crowd to synchronize videos performing small tasks. The LiveSync Tool, developed to test if the crowd can be used to synchronize live streaming events, is detailed and shows how to use the structure to synchronize live strems. Last but not least, the focus of the paper is to show that the crowd can be used in scenarios where automatic techniques may find challenges, not to state that the use of the crowd is better than the automatic techniques.
