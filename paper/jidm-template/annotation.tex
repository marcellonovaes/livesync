The paper Video Summarization via Crowdsourcing \cite{wu2011video} uses the crowd to identify the main occurrences in a video and thus generating a summary. In Efficiently Scaling up Crowdsourced Video Annotations \cite{vondrick2013efficiently} the crowd is used to annotate multiple videos. Through an interface provided by the authors, users can annotate videos using graphic tools, classifying objects in a video. Besides the annotation, which uses crowdsourcing, the paper presents a complementary approach that helps in annotating videos. Authors use annotations from the crowd as an input to an algorithm that automatically finalizes annotations from a video.

Generating Annotations for How-to Videos Using Crowdsourcing \cite{nguyen2013generating} also uses the crowd to generate annotations, however, in this case within a specific context. Authors divide the annotation task in three steps: identifying the time when important events occur; name each event; and identify frames indicating instants before and after the event, helping in the How-To.

Crowdsourcing event detection in YouTube video \cite{steiner2011crowdsourcing} focuses in generally identifying events in a YouTube video. It features processing in video playback time, to identify scene changes, and then allowing a viewer to annotate that part of the video. However, as stated by authors: "Regarded in isolation, neither of our video event analysis steps is new". Its contributions are in: (i) scalability through crowdsourcing, (ii) the nature of real time processing in a HTML5 client, and (iii) the combination of annotations for three different types of events (visual event, occurrence event and interest-based event).

A web-based video annotation system for crowdsourcing surveillance videos \cite{gadgil2014web} presents a platform for annotating surveillance videos. A supervisor selects and assigns tasks to users. The paper, despite using the term crowdsourcing	, uses the concept of outsourcing, once results from the crowd are not evaluated, neither combined to generate the result. Each individual has to watch the entire surveillance video and annotate it, falling back to the large tasks problem.

Tagging human activities in video by crowdsourcing \cite{nguyen2013tagging} uses the crowd to annotate scenes in a video, where each participant must annotate its start, end and details of its content to generate an annotation.