
LiveSync is an method to achieve video synchronization for live streams from multiply sources. The application scenario involves an event registered for multiply users, that transmit the event through live video streams. These users can be amateurs generating videos spontaneously, without a plan or previous definitions. In other words, they potentially transmit UGV live streams. The different UGV live streams can be asynchronous, so they must be synchronized to be consistently presented, or to generate a coherent composition on them. Although UGVs use to be heterogeneous, with different audio information, backgrounds, camera motion among other issues that make this scenario unsuitable for automatic methods \cite{schweiger2013fully}.

Automatic methods usually present good efficiency and accuracy using image, audio or video marks, as well objects detection as approach to synchronize videos \cite{key:article}. However, this class of methods commonly uses a machine learning approach, that demands well structured videos and a large example library to work properly \cite{KarpathyCVPR14}. These techniques has obtained very promising results for video description and classification in sport games, advertisements or TV series, which offers similar audiovisual content (in terms of structure, concept, objects, features and others elements) for successive transmissions of this kind of streaming \cite{6909619}. Although, while automatic methods have problems relating heterogeneous videos,  human being usually can deal with this kind of content. In this way is correct affirm that synchronize a pair of UGV tends to be a difficult task for automatic methods but easy for humans. Based on this, LiveSync was designed over a method that uses human contributions to synchronize pairs of UGVs, and process these contributions to synchronize a set of UGV live streams.

The user contributions are collected by a mash-up application in which all UGV live streams are grouped, and which provides a player with specific functionalities to allows the user to find out a synchronization point for a pair of video streams and submit it. Moreover the same application provides a different view that aligns the synchronized UGVs and displays them to users.

Video live streams are associated to real-time delivery, so it is an important characteristic of LiveSync allow users to play the streams while attempt to find synchronization points between then. In this way, users can consume this live content while performing their contribution tasks.

When performing a synchronizing task, the user don't need analyses entire videos seeking for synchronization point. An user can simply use the buttons Play and Pause on the video player until both videos are playing synchronously. Once the user achieved a local synchronism to a pair of videos, the application measure the delay between them and registers it as a $\Delta{time}$ contribution. All contributions are registered, and used as input to calculate the delay between each pair of videos that will likely satisfy users.

As soon as a pair of videos are synchronized, the application registers this synchronization and align the videos in a visualization interface with the other synchronized videos. So, anyone may access this view and watch the synchronized videos in an aligned view.
